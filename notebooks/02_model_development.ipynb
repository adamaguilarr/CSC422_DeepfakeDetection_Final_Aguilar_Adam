{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3fb38a34",
   "metadata": {},
   "source": [
    "# 02 – Model Development: Deepfake Detection\n",
    "\n",
    "Goal: extract image frames from videos, build a train/val split, and prepare data\n",
    "loaders for a CNN based deepfake classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a830efe8",
   "metadata": {},
   "source": [
    "Imports and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ba5cb98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 2.9.1+cpu\n",
      "CUDA available: False\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import torchvision.transforms as T\n",
    "import torchvision.models as models\n",
    "\n",
    "print(\"Torch version:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85539717",
   "metadata": {},
   "source": [
    "Load metadata again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eda0d401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adamc\\Documents\\Fall 25\\Machine and Deep Learning\\CSC422_DeepfakeDetection_Final_Aguilar_Adam\\data\\raw\\train_sample_videos\\metadata.json True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(         filename label        original\n",
       " 0  aagfhgtpmv.mp4  FAKE  vudstovrck.mp4\n",
       " 1  aapnvogymq.mp4  FAKE  jdubbvfswz.mp4\n",
       " 2  abarnvbtwb.mp4  REAL            None\n",
       " 3  abofeumbvv.mp4  FAKE  atvmxvwyns.mp4\n",
       " 4  abqwwspghj.mp4  FAKE  qzimuostzz.mp4,\n",
       " label\n",
       " FAKE    323\n",
       " REAL     77\n",
       " Name: count, dtype: int64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# project root is one level up from notebooks/\n",
    "project_root = Path(\"..\").resolve()\n",
    "\n",
    "# data/raw under project root\n",
    "data_root = project_root / \"data\" / \"raw\"\n",
    "\n",
    "meta_path = data_root / \"train_sample_videos\" / \"metadata.json\"\n",
    "print(meta_path, meta_path.exists())   # should print ...metadata.json True\n",
    "\n",
    "with open(meta_path, \"r\") as f:\n",
    "    meta = json.load(f)\n",
    "\n",
    "rows = []\n",
    "for fname, info in meta.items():\n",
    "    rows.append(\n",
    "        {\n",
    "            \"filename\": fname,\n",
    "            \"label\": info[\"label\"],          # \"FAKE\" or \"REAL\"\n",
    "            \"original\": info.get(\"original\") # original real video, if available\n",
    "        }\n",
    "    )\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "df.head(), df[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40951c11",
   "metadata": {},
   "source": [
    "Create processed frame folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d67ab78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('data/processed/frames/train')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames_root = Path(\"data/processed/frames\")\n",
    "train_frames_root = frames_root / \"train\"\n",
    "\n",
    "for label in [\"REAL\", \"FAKE\"]:\n",
    "    (train_frames_root / label).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "train_frames_root"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c51dda",
   "metadata": {},
   "source": [
    "Helper to extract a center frame from each video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f9de453",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_center_frame(video_path: Path, out_path: Path) -> bool:\n",
    "    cap = cv2.VideoCapture(str(video_path))\n",
    "    if not cap.isOpened():\n",
    "        print(\"Could not open\", video_path)\n",
    "        return False\n",
    "\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    if frame_count == 0:\n",
    "        cap.release()\n",
    "        print(\"No frames in\", video_path)\n",
    "        return False\n",
    "\n",
    "    center_idx = frame_count // 2\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, center_idx)\n",
    "    ok, frame = cap.read()\n",
    "    cap.release()\n",
    "\n",
    "    if not ok:\n",
    "        print(\"Could not read frame from\", video_path)\n",
    "        return False\n",
    "\n",
    "    # OpenCV is BGR, but for saving jpg it is fine to keep BGR\n",
    "    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    cv2.imwrite(str(out_path), frame)\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309b3e11",
   "metadata": {},
   "source": [
    "Run frame extraction (one per video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b67fee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\adamc\\Documents\\Fall 25\\Machine and Deep Learning\\CSC422_DeepfakeDetection_Final_Aguilar_Adam\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "100%|██████████| 400/400 [01:49<00:00,  3.67it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(400, 0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "success = 0\n",
    "fail = 0\n",
    "\n",
    "for row in tqdm(df.itertuples(), total=len(df)):\n",
    "    fname = row.filename\n",
    "    label = row.label.upper()          # \"REAL\" or \"FAKE\"\n",
    "\n",
    "    video_path = data_root / \"train_sample_videos\" / fname\n",
    "    out_name = fname.replace(\".mp4\", \".jpg\")\n",
    "    out_path = train_frames_root / label / out_name\n",
    "\n",
    "    # Skip if we already extracted this frame\n",
    "    if out_path.exists():\n",
    "        continue\n",
    "\n",
    "    if extract_center_frame(video_path, out_path):\n",
    "        success += 1\n",
    "    else:\n",
    "        fail += 1\n",
    "\n",
    "success, fail"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
